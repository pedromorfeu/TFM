1. Registration in Databricks
2. MLlib has features for classification, regression, collaborative filtering, clustering, and decomposition (SVD and PCA) (http://www.kdnuggets.com/2014/07/mllib-apache-spark-component-machine-learning.html)
3. Aprendizaje no supervisado: Reducción de la dimensionalidad. Proyectar los datos desde un espacio de alta dimensionalidad (d >> 10) a dos o tres dimensiones para visualizar los datos. O a un rango inferior (d' < 20) para aplicar otras técnicas de regresión o clasificación.
4. http://scikit-learn.org/stable/modules/decomposition.html#principal-component-analysis-pca
5. http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA
6. "If we're going to only see the data along one dimension, though, it might be better to make that dimension the principal component with most variation. We don't lose much by dropping PC2 since it contributes the least to the variation in the data set." (http://setosa.io/ev/principal-component-analysis/)
7. http://www.real-statistics.com/students-t-distribution/two-sample-t-test-uequal-variances/
8. http://www.real-statistics.com/multivariate-statistics/boxs-test-equality-covariance-matrices/boxs-test-basic-concepts/
9. https://cran.r-project.org/web/packages/Hotelling/Hotelling.pdf
10. http://people.stat.sc.edu/hansont/stat730/paketo-libre.pdf
11. http://www.ibm.com/support/knowledgecenter/SSLVMB_24.0.0/spss/tutorials/glmm_patlos_homcov.html
12. http://oak.ucc.nau.edu/rh232/courses/EPS625/Handouts/Interpreting%20the%20One-way%20MANOVA.pdf
13. "one first chooses a model (the null hypothesis) and a threshold value for p, called the significance level of the test, traditionally 5% or 1% [6] and denoted as α. If the p-value is less than or equal to the chosen significance level (α), the test suggests that the observed data is inconsistent with the null hypothesis, so the null hypothesis must be rejected." (https://en.wikipedia.org/wiki/P-value)
14. "The following assumptions are made when using T2: 1. Each population follows the multivariate normal distribution. 2. The two samples are independent. 3. The two covariance matrices are equal" (http://ncss.wpengine.netdna-cdn.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Hotellings_Two-Sample_T2.pdf)
15. "Box's M tests "the assumption ... that the vector of the dependent variables follow a multivariate normal distribution, and the variance-covariance matrices are equal across the cells formed by the between-subjects effects." (SPSS 14 Help - Tutorial)" (https://en.wikiversity.org/wiki/Box%27s_M)
16. "When a P value is less than or equal to the significance level, you reject the null hypothesis." (http://blog.minitab.com/blog/adventures-in-statistics/understanding-hypothesis-tests:-significance-levels-alpha-and-p-values-in-statistics)
17. "The p-value for the test is less than 0.0001 indicating that we reject the null hypothesis." (http://sites.stat.psu.edu/~ajw13/stat505/fa06/11_2sampHotel/11_2sampHotel_assump.html)
18. "Hotelling's T2 Statistic: If the observed T2 value is 'large' we reject H0:mu=mu0" (http://www.public.iastate.edu/~maitra/stat501/lectures/InferenceForMeans-Hotelling.pdf)
19. "Checking out the Box’s M test we find that the test is significant (which means that there are significant differences among the regions in the covariance matrices)" (https://www.google.es/url?sa=t&rct=j&q=&esrc=s&source=web&cd=6&ved=0ahUKEwiJn9P2_rvPAhVJfiYKHeW_A8AQFgg8MAU&url=http%3A%2F%2Fwww-bcf.usc.edu%2F~mmclaugh%2F550x%2FPPTslides%2FWeekElevenSlides%2FMANOVA.ppt&usg=AFQjCNGuG6lhm_BflMGHKaNLQYzrIYNKwg&sig2=Qw-dDc-JHFODF2_NwFtM0w&cad=rja)
20. "Large variances have important dynamics. This assumption also encompasses the belief that the data has a high SNR. Hence, principal components with larger associated variances represent interesting dynamics, while those with lower variancees represent noise." (PCA-Tutorial-Intuition_jp.pdf)
21. Noise (https://www.cs.cmu.edu/~bapoczos/other_presentations/PCA_24_10_2009.pdf)
22. Monte Carlo: "repeated random sampling to obtain numerical results"; "Monte Carlo–based predictions of failure, cost overruns and schedule overruns are routinely better than human intuition or alternative "soft" methods."; "In principle, Monte Carlo methods can be used to solve any problem having a probabilistic interpretation" (https://en.wikipedia.org/wiki/Monte_Carlo_method)
23. "In statistics, a moving average is a calculation to analyze data points by creating series of averages of different subsets of the full data set"; "Given a series of numbers and a fixed subset size, the first element of the moving average is obtained by taking the average of the initial fixed subset of the number series. Then the subset is modified by "shifting forward"; that is, excluding the first number of the series and including the next number following the original subset in the series. This creates a new subset of numbers, which is averaged. This process is repeated over the entire data series"; "In financial applications a simple moving average (SMA) is the unweighted mean of the previous n data" (https://en.wikipedia.org/wiki/Moving_average)


PCA selecciona las componentes de mayor varianza.
PCA elige la componente que más maximiza la varianza, luego la siguiente y así sucesivamente.
Hemos de tener en cuenta que la primera componente es la que más varianza explica, la segunda es la siguiente en explicación habiendo quitado la varianza de la primera

Orthogonal projection of data onto lower-dimension linear space that:
• maximizes variance of projected data (purple line)
• minimizes mean squared distance between
    • data point and
    • projections (sum of blue lines) (see Bishop diagram)

Email:
Una vez constatemos que ambas poblaciones pueden considerarse estadísticamente idénticas deberías de pasar a generar muestras a periodos más o menos regulares. Pero atención, como los datos seguirán algún tipo de patrón temporal debería de aprenderse la serie temporal para cada componente principal previamente y generar cada componente con la serie aprendida para ella, también se debería de generar algo de ruido en la señal, dicho ruido podría establecerse por ejemplo a partir de: el error de predicción de la serie o mediante las componentes principales que hayamos dejado.

TODO:
- asignatura "Taller lenguajes programación" - numpy + matplotlib
- asignatura "Ampliación lenguajes programación" - numpy + matplotlib
- Bishop http://www.miketipping.com/papers/met-mppca.pdf
- read/write MongoDB Python/R