1. Registration in Databricks
2. MLlib has features for classification, regression, collaborative filtering, clustering, and decomposition (SVD and PCA) (http://www.kdnuggets.com/2014/07/mllib-apache-spark-component-machine-learning.html)
3. Aprendizaje no supervisado: Reducción de la dimensionalidad. Proyectar los datos desde un espacio de alta dimensionalidad (d >> 10) a dos o tres dimensiones para visualizar los datos. O a un rango inferior (d' < 20) para aplicar otras técnicas de regresión o clasificación.
4. http://scikit-learn.org/stable/modules/decomposition.html#principal-component-analysis-pca
5. http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA
6. "If we're going to only see the data along one dimension, though, it might be better to make that dimension the principal component with most variation. We don't lose much by dropping PC2 since it contributes the least to the variation in the data set." (http://setosa.io/ev/principal-component-analysis/)
7. http://www.real-statistics.com/students-t-distribution/two-sample-t-test-uequal-variances/
8. http://www.real-statistics.com/multivariate-statistics/boxs-test-equality-covariance-matrices/boxs-test-basic-concepts/
9. https://cran.r-project.org/web/packages/Hotelling/Hotelling.pdf
10. http://people.stat.sc.edu/hansont/stat730/paketo-libre.pdf
11. http://www.ibm.com/support/knowledgecenter/SSLVMB_24.0.0/spss/tutorials/glmm_patlos_homcov.html
12. http://oak.ucc.nau.edu/rh232/courses/EPS625/Handouts/Interpreting%20the%20One-way%20MANOVA.pdf
13. "one first chooses a model (the null hypothesis) and a threshold value for p, called the significance level of the test, traditionally 5% or 1% [6] and denoted as α. If the p-value is less than or equal to the chosen significance level (α), the test suggests that the observed data is inconsistent with the null hypothesis, so the null hypothesis must be rejected." (https://en.wikipedia.org/wiki/P-value)
14. "The following assumptions are made when using T2: 1. Each population follows the multivariate normal distribution. 2. The two samples are independent. 3. The two covariance matrices are equal" (http://ncss.wpengine.netdna-cdn.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Hotellings_Two-Sample_T2.pdf)
15. "Box's M tests "the assumption ... that the vector of the dependent variables follow a multivariate normal distribution, and the variance-covariance matrices are equal across the cells formed by the between-subjects effects." (SPSS 14 Help - Tutorial)" (https://en.wikiversity.org/wiki/Box%27s_M)
16. "When a P value is less than or equal to the significance level, you reject the null hypothesis." (http://blog.minitab.com/blog/adventures-in-statistics/understanding-hypothesis-tests:-significance-levels-alpha-and-p-values-in-statistics)
17. "The p-value for the test is less than 0.0001 indicating that we reject the null hypothesis." (http://sites.stat.psu.edu/~ajw13/stat505/fa06/11_2sampHotel/11_2sampHotel_assump.html)
18. "Hotelling's T2 Statistic: If the observed T2 value is 'large' we reject H0:mu=mu0" (http://www.public.iastate.edu/~maitra/stat501/lectures/InferenceForMeans-Hotelling.pdf)
19. "Checking out the Box’s M test we find that the test is significant (which means that there are significant differences among the regions in the covariance matrices)" (https://www.google.es/url?sa=t&rct=j&q=&esrc=s&source=web&cd=6&ved=0ahUKEwiJn9P2_rvPAhVJfiYKHeW_A8AQFgg8MAU&url=http%3A%2F%2Fwww-bcf.usc.edu%2F~mmclaugh%2F550x%2FPPTslides%2FWeekElevenSlides%2FMANOVA.ppt&usg=AFQjCNGuG6lhm_BflMGHKaNLQYzrIYNKwg&sig2=Qw-dDc-JHFODF2_NwFtM0w&cad=rja)
20. "Large variances have important dynamics. This assumption also encompasses the belief that the data has a high SNR. Hence, principal components with larger associated variances represent interesting dynamics, while those with lower variancees represent noise." (PCA-Tutorial-Intuition_jp.pdf)
21. Noise (https://www.cs.cmu.edu/~bapoczos/other_presentations/PCA_24_10_2009.pdf)
22. Monte Carlo: "repeated random sampling to obtain numerical results"; "Monte Carlo–based predictions of failure, cost overruns and schedule overruns are routinely better than human intuition or alternative "soft" methods."; "In principle, Monte Carlo methods can be used to solve any problem having a probabilistic interpretation" (https://en.wikipedia.org/wiki/Monte_Carlo_method)
23. "In statistics, a moving average is a calculation to analyze data points by creating series of averages of different subsets of the full data set"; "Given a series of numbers and a fixed subset size, the first element of the moving average is obtained by taking the average of the initial fixed subset of the number series. Then the subset is modified by "shifting forward"; that is, excluding the first number of the series and including the next number following the original subset in the series. This creates a new subset of numbers, which is averaged. This process is repeated over the entire data series"; "In financial applications a simple moving average (SMA) is the unweighted mean of the previous n data" (https://en.wikipedia.org/wiki/Moving_average)
24. ARIMA: "The I (for "integrated") indicates that the data values have been replaced with the difference between their values and the previous values" (https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)
25. Regression: "The phenomenon was that the heights of descendants of tall ancestors tend to regress down towards a normal average (a phenomenon also known as regression toward the mean)" (https://en.wikipedia.org/wiki/Regression_analysis#History)
26. ARIMA: "In MA model, noise / shock quickly vanishes with time. The AR model has a much lasting effect of the shock." (https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/)
27. Stochastic process: "A stochastic process is a random process evolving with time." (https://en.wikipedia.org/wiki/Stochastic_process)
28. Stationary: "A stationary process is a stochastic process whose parameters such as mean and variance, if they are present, also do not change over time."; "Since Stationarity is an assumption underlying many statistical procedures used in time series analysis, non-stationary data is often transformed to become stationary."; "is not a function of time"; "As an example, white noise is stationary. The sound of a cymbal clashing, if hit only once, is not stationary because the acoustic power of the clash (and hence its variance) diminishes with time. However, it would be possible to invent a stochastic process describing when the cymbal is hit, such that the overall response would form a stationary process." (https://en.wikipedia.org/wiki/Stationary_process)
29. PCA: PCA selecciona las componentes de mayor varianza. PCA elige la componente que más maximiza la varianza, luego la siguiente y así sucesivamente. Hemos de tener en cuenta que la primera componente es la que más varianza explica, la segunda es la siguiente en explicación habiendo quitado la varianza de la primera. Orthogonal projection of data onto lower-dimension linear space that:
    • maximizes variance of projected data (purple line)
    • minimizes mean squared distance between
        • data point and
        • projections (sum of blue lines) (see Bishop diagram)
30. Autoregressive models: "In an autoregression model, we forecast the variable of interest using a linear combination of past values of the variable." (https://www.otexts.org/fpp/8/3)
31. Moving average models: "Rather than use past values of the forecast variable in a regression, a moving average model uses past forecast errors in a regression-like model." (https://www.otexts.org/fpp/8/4)
32. Stationarity and differencing: "This shows one way to make a time series stationary — compute the differences between consecutive observations. This is known as differencing."; "Transformations such as logarithms can help to stabilize the variance of a time series. Differencing can help stabilize the mean of a time series by removing changes in the level of a time series, and so eliminating trend and seasonality. As well as looking at the time plot of the data, the ACF plot is also useful for identifying non-stationary time series. For a stationary time series, the ACF will drop to zero relatively quickly, while the ACF of non-stationary data decreases slowly." (https://www.otexts.org/fpp/8/1)
33. Avoid seasonality? Because the metrics frequency isn't regular.
34. Time series Modelling procedure:
    "1. Plot the data. Identify any unusual observations.
    2. If necessary, transform the data (using a Box-Cox transformation) to stabilize the variance.
    3. If the data are non-stationary: take first differences of the data until the data are stationary.
    4. Examine the ACF/PACF: Is an AR(pp) or MA(qq) model appropriate?
    5. Try your chosen model(s), and use the AICc to search for a better model.
    6. Check the residuals from your chosen model by plotting the ACF of the residuals, and doing a portmanteau test of the residuals. If they do not look like white noise, try a modified model.
    7. Once the residuals look like white noise, calculate forecasts."
    (https://www.otexts.org/fpp/8/7)
35. Time series: "TS different from say a regular regression problem? It is time dependent. So the basic assumption of a linear regression model that the observations are independent doesn’t hold in this case."; "The underlying principle is to model or estimate the trend and seasonality in the series and remove those from the series to get a stationary series. Then statistical forecasting techniques can be implemented on this series. The final step would be to convert the forecasted values into the original scale by applying trend and seasonality constraints back."; "Smoothing refers to taking rolling estimates, i.e. considering the past few instances. " (https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/)
36. Google search: "time series analysis missing data"; "python time series irregular frequency"
37. Time series: "Time series analysis accounts for the fact that data points taken over time may have an internal structure (such as autocorrelation, trend or seasonal variation) that should be accounted for." (http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4.htm)
38. "Definition of Time Series: An ordered sequence of values of a variable at equally spaced time intervals."; "some basic smoothing techniques: Averaging Methods and Exponential Smoothing Techniques." (http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc41.htm)
39. "The estimator with the smallest MSE is the best."; "The "simple" average or mean of all past observations is only a useful estimate for forecasting when there are no trends. If there are trends, use different estimates that take the trend into account. The average "weighs" all past observations equally." (http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc42.htm)
40. "If the data are equi-spaced, the time variable, or index, does not need to be explicitly given. The time variable may sometimes be explicitly used for plotting the series. However, it is not used in the time series model itself." (http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc44.htm)
41. "A stationary process has the property that the mean, variance and autocorrelation structure do not change over time."; "transform it to stationarity with one of the following techniques.
    1. We can difference the data. That is, given the series Zt, we create the new series Yi=Zi−Zi−1. The differenced data will contain one less point than the original data. Although you can difference the data more than once, one difference is usually sufficient.
    2. If the data contain a trend, we can fit some type of curve to the data and then model the residuals from that fit. Since the purpose of the fit is to simply remove long term trend, a simple fit, such as a straight line, is typically used.
    3. For non-constant variance, taking the logarithm or square root of the series may stabilize the variance. For negative data, you can add a suitable constant to make all the data positive before applying the transformation. This constant can then be subtracted from the model to obtain predicted (i.e., the fitted) values and forecasts for future points." (http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc442.htm)
42. "What to Do about Missing Values in Time-Series Cross-Section Data" (http://gking.harvard.edu/files/pr.pdf)
43. "Online Time Series Prediction with Missing Data" (http://jmlr.org/proceedings/papers/v37/anava15.pdf)
44. Time series: "ARIMA models are defined for stationary time series. Therefore, if you start off with a non-stationary time series, you will first need to ‘difference’ the time series until you obtain a stationary time series. If you have to difference the time series d times to obtain a stationary series, then you have an ARIMA(p,d,q) model, where d is the order of differencing used."; "If we use the “bic” criterion, which penalises the number of parameters" (http://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/src/timeseries.html)


Email:
Una vez constatemos que ambas poblaciones pueden considerarse estadísticamente idénticas deberías de pasar a generar muestras a periodos más o menos regulares. Pero atención, como los datos seguirán algún tipo de patrón temporal debería de aprenderse la serie temporal para cada componente principal previamente y generar cada componente con la serie aprendida para ella, también se debería de generar algo de ruido en la señal, dicho ruido podría establecerse por ejemplo a partir de: el error de predicción de la serie o mediante las componentes principales que hayamos dejado.

TODO:
- asignatura "Taller lenguajes programación" - numpy + matplotlib
- asignatura "Ampliación lenguajes programación" - numpy + matplotlib
- Bishop http://www.miketipping.com/papers/met-mppca.pdf
- read/write MongoDB Python/R
- Books:
    - Pattern Recognition And Machine Learning (Bishop)
    - Introduction to Statistical Learning (James, Witten, Hastie, Tibshirani)
    - Time Series Analysis - Forecasting and Control (Box)
    - Introduction Time Series and Forecasting (Brockwell, Davis)